# Redis系统学习(二)

## Redis持久化流程

1. 客户端向服务端发送写操作。**（数据在客户端的内存中）**
2. 数据库服务端收到客户端写请求发来的数据。**（数据在服务端的内存中）**
3. 服务端调用write这个系统调用，将数据往磁盘中写。**（数据在系统内存的缓冲区中）**
4. 操作系统将缓冲区中的数据转移到磁盘控制器上。**（数据在磁盘缓存中）**
5. 磁盘控制器将数据写到磁盘的物理介质中。**（数据真正落实到磁盘中）**

- ### 遇到的问题：

   上述过程是在理想状态下的过程，但是大多数情况下，机器会有各种各样的故障，这里划分了两种情况。

  1.  Redis数据库发生故障，只要上述三步完成，后面的两步由操作系统替我们完成。
  2. 操作系统发生故障，必须上面5步全部完成。



## Redis持久化的两种方式

​    Redis如何实现上述5个保存到磁盘的步骤？

- ### RDB(Redis DataBase)

  #### 概念：

  ​    将数据以快照形式保存在磁盘上。快照，可以理解为把即刻的数据拍成一张照片保存下来。

  ​    RDB持久化是指在指定的时间间隔内将数据集快照写入磁盘。也是**默认的持久化方式，就是将内存中的数据以快照的方式写入到二进制文件中，默认的文件名为dump.rdb。.**

  ​    ps: 在redis.conf配置文件中含有RDB和AOF两种持久化数据机制的各种配置。

  ​    对于RDB的持久化方式，提供了三种机制：**save，bgsave，自动化。**

  - **save触发方式**

    该命令会阻塞当前Redis服务器，即执行save命令期间不能执行其他命令，此时其他客户端向redis服务器发出的请求都会被阻塞，必须当RDB全部执行完毕之后才可以处理其他请求。

    执行完成的时候如果存在老的RDB（二进制）文件，会用新的文件代替旧的文件。但是我们的客户端都是几万或者几十万的请求，这种方式显然不可取。

  - **bgsave触发方式**

    该命令会异步的处理bgsave命令以及其他客户端的命令，在开始进行bgsave命令时，**redis进程执行fork操作创建一个子进程**，子进程负责执行RDB的持久化过程，完成后自动结束。阻塞只发生在fork阶段，一般时间很短。基本上Redis内部所有的RDB操作都是采用bgsave命令。

  - **自动化触发方式**

  #### 优势：

  1. RDB文件紧凑，全量备份，非常适合用于备份和灾难恢复。
  2. 在生成RDB文件的时候，主进程会fork一个子进程来执行，主进程不需要进行任何磁盘的io操作。
  3. 在恢复大量数据集的时候，速度比AOF快。

  #### 劣势：

    RDB快照是一次全量备份，存储的是内存数据的二进制序列化形式，存储上非常紧凑。当进行快照持久化时，会开启一个子进程专门负责快照持久化，子**进程会拥有父进程的内存数据，父进程修改内存子进程不会反应出来，所以在快照持久化期间修改的数据不会被保存，可能丢失数据。**

  

- ### AOF(Append Only File)

  ####  概念：

  ​     全量备份总是耗时的，这里有一种更加高效的方式--AOF。

  ​     **工作机制：redis会将收到的每一个写命令都通过write函数追加到文件中。通俗的理解就是日志记录。**

  ####  持久化原理：

  ​    ![img](https://pics3.baidu.com/feed/32fa828ba61ea8d3c2502e396b1b3848251f58b0.jpeg?token=394597ccd73bd15778c518b5c5be6998&s=2D62E7169D305F8A847546E20200B036)

  ​    

  ​    每有一个写命令传过来，就将其直接保存在AOF文件中。

  ####  文件重写原理：

  ​    AOF会带来的一个问题--持久化文件会越来越大。

     **为了压缩持久化文件**，redis提供了bgwriteaof命令--将内存中的数据以命令的方式保存在临时文件中，同时会fork出一条新的进程将文件重写。

    ![img](https://pics7.baidu.com/feed/09fa513d269759ee28454d2c4cea4b106c22dfd3.jpeg?token=86eda46b8bcd54a7a0e7d8a37d87bee8&s=EDB2A4579D317B824660D4DF0200E036)

  ​      

  #### AOF的三种触发机制：

  1. 每修改同步always：

     ​    **同步持久化，每次发生数据变更会立即记录到磁盘，性能比较差但是数据的完整性比较好。**

  2. 每秒同步everysec：

     ​    **异步操作，每秒记录，如果一秒内宕机，有数据丢失。**

  3. 不同no：

        **从不同步**

  ​    ![img](https://pics5.baidu.com/feed/b17eca8065380cd7df69859ba056a5325982816c.jpeg?token=a060f459d81c409c3d6c7208d2118888&s=AF4AA5574ED85CC841D04BE60300A036)




#### rewrite操作

   因为AOF文件只会生成一份，随着内存中的数据越来越多，持久化的数据越来越多，AOF文件也会越来越大。

   而当redis中的数据越来越多之后，会进行一个过期键的处理，比如可能用到内存淘汰机制来删除过期的键。

   AOF rewrite操作，会给予当时redis中的数据，来重新构造一个更小的AOF文件，然后将就得膨胀的很大的文件给删了。







#### 优点：

1.  可以更好地保护数据不被丢失，一般AOF会每隔一秒，通过一个后台线程执行一次fsync操作，最多丢失一秒的数据。
2. AOF日志文件没有任何磁盘寻址的开销，写入性能非常高，文件不容易破损。
3. AOF日志文件即使过大的时候，引起后台的重写，也不会影响客户端的读写操作。
4. AOF日志文件的命令通过非常可读的方式记录，这个特此非常适合做灾难性的误删除的紧急恢复。若某人不小心用flushall命令清空了所有数据，只要后台的rewrite还没有发生，就可以拷贝AOF文件，将最后一条flushall命令删掉，然后再将AOF文件放回去，就可以通过恢复机制，自动恢复所有数据。

#### 缺点：

1. 对于同一份数据来说，AOF日志文件通常比RDB数据快照文件更大。

2. AOF开启之后，支持的写QPS比RDB的QPS更低，因为AOF一般会设置成每秒进行一次fsync，当然，一秒进行一次fsync，效率还是很高的。

     ps：QPS（Query Per Second）：每秒查询率

3. 在通过AOF的日志记录恢复数据时，有时候不能恢复出一模一样的数据来。

#### RDB和AOF的选择问题：

   ![img](https://pics5.baidu.com/feed/8326cffc1e178a82c532308ef2117b8ba977e8ae.jpeg?token=fea28817e45f0e091b5be3854d856fbb&s=BD48B55F1C784C095E61DCEB0300D036)





## Redis：过期键删除策略

- ### 定时删除：

     在设置键的过期时间的同时，创建一个定时器，让定时器在键的过期时间来临时，立即删除该键。

- ### 定期删除：

     每隔一段时间，程序就会对数据库进行一次检查，删除里面的过期键。至于要删除多少个键，以及要检查多少个数据库，根据算法而定。



- ### 惰性删除：

  放任键不管，但是每次获取键的时候就会判断当前键是否过期，如果检测到键已经过期，就删除该键。

  注意，上述三种处理方式，前两种为主动删除，第三种为被动删除策略。

  

  ### 1.定时删除

  ​       **优点：**定时删除策略对内存是最友好的，通过设置过期时间及时的删除过期键，能够保证无用的键及时的被删除。                                                                                                                                                                                                                                                                                                                                                                                  

  ​       **缺点：**对cpu时间是最不友好的：在过期键比较多的情况下，删除过期键这一行为可能会占用相当一部分时间。

  ​                   因为设置定时器需要使用Redis服务器的时间事件，底层实现用到的是无序列表，处理的时间复杂度为O(N),这样并不能高效的处理。

  ### 2.惰性删除

  ​       优点：对cpu时间来说是最友好的：程序只会在取出键的情况下才会对键进行过期检查，这可以保证删除过期键的操作只会在非做不可的情况下才进行，并且删除的目标仅限于当前处理的键，这个策略不会在删除其他无关的过期键上花费任何时间。

  ​       缺点：对内存来说是最不友好的：如果一个键已经过期，而这个键又仍然保留在数据库，只要这个过期键不被删除，它占用的内存就不会删除。

  ### 3.定期删除

  定期删除是前两种策略的一种整合和折中：

  - **对cpu的好处：**定期删除策略每隔一段时间来检查并删除过期键，并通过限制删除过期键的时间和频率来减少删除操作对cpu时间的影响。

  - **对内存的好处**：通过定期删除键，有效的减少了因为过期键而带来的内存浪费。

  - 难点：怎样确定删除操作执行的时长和频率：

    - 如果操作执行的太频繁，定期删除策略会退化成定时删除策略，以至于CPU时间过多的消耗在删除过期键上面。
    - 如果删除操作执行的太少，或者执行的时间过短，定期删除策略又会和惰性删除删除策略一样，出现浪费内存的情况。

    

    

    

    ## Redis的过期键处理策略

    redis服务器实际使用的是**惰性删除和定期删除**两种策略：通过配合使用这两种策略，服务器何以很好的在合理使用cpu和避免浪费内存之间取得一个平衡。

    ### 1.惰性删除策略的实现

    过期键的惰性删除策略由db.c/expireIfNeeded函数实现，所有读写数据库额的命令在执行之前都会调用expireIfNeeded函数对输入键检查。

    - 如果已经过期，eiN函数将输入键从函数中删除；
    - 如果未过期，那么eiN函数不操作

    ### 2.定期删除策略的实现

    过期键的定期删除有redis.c/activeExpireCycle函数实现，每当redis服务器周期性操作redis.c/serverCron函数执行时，activeExpireCycle函数就会被调用，在规定的时间内，分多次遍历服务器中的各个数据库，从数据库的expire字典中随机检查一部分键的过期时间，并删除其中的过期键。

    

    activeExpireCycle函数的工作过程：

    - 函数每次执行时，会从数据库中取出一定量的随机键进行检查，检查数据库中的过期键并将其删除；
    - 在redis中有一个全局变量current_db,用于记录activeExpireCycle函数删除的进度，等下一次检查时，会根据进度继续检查删除。
    - 通过上述的过程，redis中的数据库将被全部遍历完，即其中的过期键将全部被删除，这时会将current.db变量的值恢复为0，然后开始新一轮的检查工作。

    ## AOF，RDB的复制功能对过期键的处理

    ### 1.生成RDB文件

      在执行save或者bgsave命令创建一个新的RDB文件时，程序会对数据库中的键进行检查，已过期的键不会保存到新创建的RDB文件中。

    ### 2.载入RDB文件

      在启动redis服务器时，如果启动了RDB功能，**服务器会对RDB文件进行载入：**

    - 如果服务器以**主服务器**模式运行，那么在载入RDB文件时，程序会对文件中保存的键进行检查，未过期的键会被载入到数据库中，而过期键会被删除，而过期键则被忽略，所以过期键对载入RDB文件的主服务器不会产生影响。

    - 如果服务器以**从服务器**模式进行，那么在载入RDB文件时，文件中保存的键，不论是否过期都会被载入到数据库中。

      但是，主从服务器在进行数据同步的时候，从服务器的数据就会被清空，所以，一般来说，过期键在载入RDB文件的从服务器也不会造成影响。

    

    ------

    

    ### 3.AOF文件的写入

    当服务器以AOF持久化模式运行时，如果数据库中的某个键已经过期，但是还没有被惰性删除或者定期删除，AOF不会因为这个键过期而产生任何影响。

    当过期键被惰性删除或者被定期删除，程序会向AOF文件追加一个DEL命令，显示的记录该键已经被删除。

    ### 4.AOF文件重写

    该过程和生成RDB文件的过程类似，在执行重写时，会检查该键是否过期，如果已经过期，该键将不会被保存到重写的AOF文件中。

    ### 5.复制

    当服务器运行在复制模下时，从服务器的过期键删除动作由主服务器控制；

    - 主服务器在删除一个过期键之后，会显示的向所有从服务器发送一条DEL指令。命令从服务器删除该过期键；
    - 从服务器即使碰到了过期键，也不会删除该键，而是继续处理未过期键一样处理过期键；
    - 从服务器只有在收到了主服务器发来的DEL命令之后，才会删除过期建。

    **为什么要由主服务器来控制过期键的删除？**

      由主服务器同一控制从服务器对过期键的删除，可以保证主从服务器之间数据的一致

    

    ## 如何保证redis的高并发和高可用

    ### redis主从架构

    ​    单机的redis，能够承载的QPS大概在上万到几万不等。

    ​    对于缓存来说，一般都是支持读高并发的。因此架构做成主从架构(master-slave),一主多从，主负责写，并且将数据复制到其他的slave结点，从节点负责读。所有的读请求全部走从节点。这样就实现了水平扩容，支撑读高并发。

      ![image-20200820105517568](C:\Users\11310\AppData\Roaming\Typora\typora-user-images\image-20200820105517568.png)

    ### redis replication的核心机制

    > [^ps：replication：复制]: 
    >
    > redis replication-->主从架构-->读写分离-->水平扩容支撑读高并发

    - redis采用**异步方式复制结**点，从redis2.8开始，slave node会周期性的确认自己每次复制的数据量。

    - slave node也可以连接其他的slave node；

    - slave node在做复制的时候，不会block master node的正常工作；

    - slave node在做复制的时候，也不会阻塞对自己的查询操作，他会用旧的数据集来提供服务；

      但是复制完成的时候，需要删除旧数据集，加载新数据集，这个时候就会暂停对外服务了。

    - slave node主要用来进行**横向扩容，做读写分离**。扩容的slave node可以提高读的吞吐量。

    #### 注意：

    ​    如果采用了主从架构，那么就需要开启master node的持久化，**并不建议采用slave node作为master node的备份**，因为如果发生了宕机，可能会引起数据的丢失，这时slave node复制到的数据也是空的，所以必须开启master node的持久化。

    ​    另外，master的各种备份方案，也是需要做的。万一本地的文件丢失了，从备份中挑选一份rdb去恢复master，这样才能却确保启动的时候是有数据的。即使采用了后续的高可用机制，slave node可以自动接管master node**，**

    **但也可能sentinel还没检测到master failure，master node就自动重启了，还是可能导致上面所有的salve node数据被清空。**

    ### 主从复制原理，断点续传，无磁盘化复制，过期key处理

    #### 主从复制原理：

       1.当启动一个slave node的时候，salve node会发送给master node一个psync命令。

       2.如果这时master node是重新连接salve node，那么master node只会将还没有传过去的数据进行复制（即部分缺少的数据）；如果是初次进行连接，那么master node会进行一次全面的复制，即进行**full resynchronization**过程。
    
3. 当master node与slave node 进行初次连接，开始full resynchronization的时候，master node会在后台开启一个线程，生成一个RDB快照文件，并将该文件传给slave node，由slave node将RDB文件持久化到本地磁盘中，再从本地磁盘加载到内存中，同时，master node会缓存客户端传来的写命令到内存中，接着master会将内存中缓存的写命令发送到slave，slave node也会同步这些数据。
    4. 如果在进行复制的时候master node和slave node断开连接，重新连接之后，**master node只会赋值给slave node 部分缺少的数据**。master如果发现slave node都来重新连接，仅仅会启动一个**rdb save**操作，用一份数据服务所有的slave node。

       ![img](http://p1.pstatp.com/large/pgc-image/fce569f83d264f19be938a9dd1347013)

    

    

    ####  断点续传：

    ​    redis从2.8开始就支持断点续传的功能。即如果master node和slave node发生连接中断，重新连接时，slave node并不会让master node重新进行数据的赋值，**而是从上次断开连接时复制的数据继续进行复制**。

    ​    在master node中维护了一个**backlog**的变量，同时slave node和master node都会保存一个**replica offset**和master run id，其中offset就保存在backlog中。**当重新连接之后，slave node会从上次连接的offset继续进行复制**，如果没有找到对应的offset，那么就会执行一次full resynchronization。

    ​    **注意：**

    ​     如果根据host+ip定位master node，是不靠谱的，如果master node重启或者数据发生了变化，那么slave node应该根据不同的run id进行区分。

    

    #### 无磁盘化复制：

      master在内存中直接创建RDB，然后发送给slave，不会在自己本地落地磁盘了。只需要在配置文件中配置：
    
    ```
    repli-diskless-sync yes
    #等待5s在开始复制，因为要等更多的slave重新连接起来
    repli-diskless-sync-delay 5
#ps：diskless：无磁盘化的
    ```

    

    #### 过期key的处理

    slave不会过期key，只会等待master过期key。

    如果master过期了一个key，或者通过LRU淘汰了一个key，那么会**模拟一条del命令发送给slave。**

    

    #### 完整的复制流程

      1.slave node在启动时，会在本地保存master node的host和ip。在redis.conf中的slaveof中配置有master node的信息。

      2.slave node内部有一个定时，每秒会检查是否有新的master node要连接和复制，如果发现，slave node就和master node进行socket连接。

      3.slave node向master node发送一条ping命令进行连接。

      4.口令认证，如果master node设置了requirepass，slave node需要发送masterauth进行口令认证。

      5.master node将数据全部复制给slave node。

      6.在之后的操作中，master node都会异步的将数据复制给slave node。

    

    #### 数据同步相关的核心机制

      **1.master和slave都会保存一个offset**

    ​      master本身会不不断的增加offset，slave自身也会不断的增加offset。slave每秒会上报自己的offset给master，同时master也会保存每个slave的offset。

    ​     **offset的主要作用？**

    ​      只有master和slave都知道互相的offset，才能知道互相之间数据不一致的情况。

      **2.backlog**

    ​      在master node中有一个backlog，默认是1Mb的大小。

    ​      master node在给slave node做复制的时候，也会将数据在backlog中同步写一份，**backlog主要是用来做全量复制中断后的增量复制的。**

      **3.master run id**

    ​      如果根据host+ip定位master node是不靠谱的，如果master node重启或者数据发生了变化，那么slave node应该根据不同的run id进行区分，如果run id不同就需要做全量赋值。 

    ​      如果需要不更改run id重启redis，可以使用redis-cli debug reload命令。

      **4.psync**

    ​        从节点使用psync从master node进行复制，psync runid offset。master node会根据自身的情况返回响应信息，可能是全量赋值，可能是增量复制（断开连接，重新连接后引发的复制）。

       

    **全量复制**
    
    - master 执行 bgsave ，在本地生成一份 rdb 快照文件。
    - master node 将 rdb 快照文件发送给 slave node，如果 rdb 复制时间超过 60秒（repl-timeout），那么 slave node 就会认为复制失败，可以适当调大这个参数(对于千兆网卡的机器，一般每秒传输 100MB，6G 文件，很可能超过 60s)
    - master node 在生成 rdb 时，会将所有新的写命令缓存在内存中，在 slave node 保存了 rdb 之后，再将新的写命令复制给 slave node。
    - 如果在复制期间，内存缓冲区持续消耗超过 64MB，或者一次性超过 256MB，那么停止复制，复制失败。
    - slave node 接收到 rdb 之后，清空自己的旧数据，然后重新加载 rdb 到自己的内存中，同时基于旧的数据版本对外提供服务。
- 如果 slave node 开启了 AOF，那么会立即执行 BGREWRITEAOF，重写 AOF。
      rdb生成、rdb通过网络拷贝、slave旧数据的清理、slave aof rewrite，很耗费时间

      如果复制的数据量在4G~6G之间，那么很可能全量复制时间消耗到1分半到2分钟

    **增量复制**
  
    - 如果全量复制过程中，master-slave 网络连接断掉，那么 slave 重新连接 master 时，会触发增量复制。
- master 直接从自己的 backlog 中获取部分丢失的数据，发送给 slave node，默认 backlog 就是1MB。
    - msater就是根据 slave 发送的 psync 中的 offset 来从 backlog 中获取数据的。

    

    #### heartbeat

       主从结点互相都会发送heartbeat的信息。

       **master默认每隔10秒发送一次heartbeat，slave node每隔1秒会发送一个heartbeat。**

    #### 异步复制

       master每次接收到写命令之后，先在内部写入数据，然后异步发送给slave node。

    

    ### redis怎样才能做到高可用？

    ​    一个slave挂掉了，是不会影响可用性的，还有其他的slave在提供相同数据下的对外的查询服务。

    ​    但是，如果master node死掉了呢？

    ​    没法写数据了，写缓存的时候，全部失效了。slave node还有什么用呢？没有master  node给他们复制数据了，系统相当于不可用了。

    ​    redis的高可用架构，叫做failover故障转移，也可以叫做主备切换。

    ​    **master node在故障时，自动监测，并且将某个slave node自动切换为master node的过程叫做主备切换。这个过程，实现了redis的主从架构下的高可用。**

    ****

    

    ### Redis哨兵集群实现高可用

    #### 哨兵的介绍

    ​     sentinel，中文名是哨兵。**哨兵是集群机构中重要的组件**，主要的功能有：

     **1.集群监控**

    ​      监控master  node和slave node是否正常工作。

     **2.消息通知**

    ​     如果某个redis实例出问题了，哨兵负责发送消息作为警报通知给管理员。

     **3.故障转移**

    ​    如果某一个master node挂掉了，会自动转移到slave node上。

     **4.配置中心**

    ​    如果故障转移发生了，通知client新的master 地址。

    

    **哨兵的核心知识**
    
    - 哨兵至少需要 3 个实例，来保证自己的健壮性。
- 哨兵 + redis 主从的部署架构，是不保证数据零丢失的，只能保证 redis 集群的高可用性。
    - 对于哨兵 + redis 主从这种复杂的部署架构，尽量在测试环境和生产环境，都进行充足的测试和演练。

    

    ### Redis哨兵主备切换的数据丢失问题与解决方案

    #### 主备切换的过程，可能会导致数据的丢失问题

      **1.异步复制导致数据丢失**

    ​        因为master-->slave的复制都是异步的，**所以可能有部分数据还没复制到slave，master就宕机了，这部分数据就丢失了**。

      **2.脑裂导致的数据丢失**

    ​       脑裂，也就是说，一个master node脱离了网络，跟其他的slave不能连接，但是实际上，master还运行着，但是这时哨兵可能会认为master宕机了，然后开启了选举机制，将其他的slave切换为master。这时，急群中就会有两个master，也就是所谓的脑裂。

    ​      虽然某个slave切换成了master，但是client可能还没来得及切换到新的master，仍然向master写旧的数据。因此旧master再次恢复的时候，会被作为一个slave挂到新的master上去，自己的数据就会被清空，重新从新的master复制数据。而新的master并没有后来client写入的数据，因此，这部分数据已经丢失了。

      

    #### 数据丢失问题的解决方案

    进行如下配置

    ```
    min-slaves-to-write 1
    min-slaves-max-lag 10
    ```

       上述配置要求至少要有一个slave，数据复制和同步的时间不能超过10秒。如果说一旦所有的slave，数据和同步的延迟都超过了10秒钟，那么这时候master就不会再接收任何的请求了。

       上述两个配置可以减少异步复制和脑裂导致的数据丢失。

    ```
    1.减少异步复制数据的丢失
       有了min-----lag这个配置，可以确保一旦slave复制数据和ack延时太长，就认为master宕机后损失的数据太多了，就会拒绝写请求，这样可以把master宕机由于部分数据未同步到slave导致的数据丢失降低到可控范围内。
    
    2.减少脑裂的数据丢失
       如果一个master出现了脑裂，跟其他的slave丢失了连接，那么上述两个配置可以确保说，如果不能继续给指定数量的slave发送数据，而且slave超过10秒没有给自己ack消息，那么就直接拒绝客户端的写请求。
       这样脑裂后的master就不会接收新的client的新数据，也就避免了数据丢失。上面的配置就确保了。，如果跟任何一个slave丢失了连接，在10秒后发现没有slave给自己ack，那么就拒绝新的请求。因此在脑裂的场景下，最多丢失10秒的数据。
    ```
   ```

    

    #### 怎样保证redis是高并发以及高可用的？

    - **sdown和odown的转换机制**

    - **哨兵集群的自动发现机制**

      ​       哨兵互相之间的发现，是通过 redis 的 pub/sub 系统实现的，每个哨兵都会往**`__sentinel__:hello`这个 channel** 里发送一个消息，这时候所有其他哨兵都可以消费到这个消息，并感知到其他的哨兵的存在。

      ​       每隔两秒钟，每个哨兵都会往自己监控的某个master+slaves对应的_sentinel_:hello channel里发送一个消息，内容是自己的host，ip和runid还有对这个master的监控配置。

      ​      每个哨兵也会监控自己监控的master+slaves对应的...channel，然后去感知到同样在监听这个master+slaves的其他哨兵的存在。

      ​      每个哨兵还会跟其他哨兵交换对这个master的监控配置，互相进行监控配置的同步。

    - **slave配置的自动纠正**

        哨兵会负责自动纠正slave的一些配置：

      ​    1.如果一个slave即将成为master node，哨兵会确保slave复制现有的master数据；

      ​    2.如果slave连接到一个错误的master上，比如故障转移之后 ，那么哨兵会确保他们连接到正确的master上。

    - **slave-->master的选举算法**

      如果一个master被认为odown了，而且majority数量的 哨兵都允许主备切换，那么某一个哨兵就会执行主备切换操作，此时首先要选举出一个slave来，会考虑slave的一些信息：
   
   ```
      1.跟master断开连接的时长
      2.0 slave优先级
      3.复制的offset
  4.run id
     ```

      ​       如果一个 slave 跟 master 断开连接的时间已经超过了**down-after-milliseconds**的 10 倍，外加 master 宕机的时长，那么 slave 就被认为不适合选举为 master。
    
      ​      接下来会对slave进行排序：
    
      1.按照slave的优先级排序。slave priority越低，优先级越高。
    
      2.如果slave priority相同，就看replica offset，哪个slave复制更多的数据，offset越靠后，优先级越高。
    
      3.如果上面两个条件都相同，那么选择一个较小的run id的slave。
    
    - **quorum和majority**
    
      每次一个哨兵要做主备切换，首先需要 quorum 数量的哨兵认为 odown，然后选举出一个哨兵来做切换，这个哨兵还得得到 majority 哨兵的授权，才能正式执行切换。
    如果 quorum < majority，比如 5 个哨兵，majority 就是 3，quorum 设置为2，那么就 3 个哨兵授权就可以执行切换。
        但是如果 quorum >= majority，那么必须 quorum 数量的哨兵都授权，比如 5 个哨兵，quorum 是 5，那么必须 5 个哨兵都同意授权，才能执行切换。

​      

    - **configuration epoch**
    
       哨兵会对一套redis master+slaves 进行监控，有相应的监控配置。
    
       执行切换的那个哨兵，会从要切换到的新master那里得到一个con----epoch，**这就是一个version号，每次切换的version号必须是唯一的**。
    
       如果第一个选举出的哨兵切换失败了，那么其他哨兵，会等待failover-timeout时间，然后接替继续执行切换，此时会重新获取一个新的configuration epoch，作为新的version号。
    
    - **configuration传播**
    
    ​        哨兵完成切换之后，会在自己本地生成最新的master配置，**然后同步给其他的哨兵，**就是之前说的**pub/sub**消息机制。
    
    ​        这里之前的version号很重要，**因为各种消息都是通过一个channel去发布和监听的，所以一个哨兵完成一次新的切换之后，新的master配置是跟着新的version号的**。
    
    ​        其他的哨兵是**根据版本号的大小**来更新自己的master配置的。


​    

​    

    ## 总结
    
    ​       redis实现高并发主要依靠主从架构，一主多从，一般来说，很对项目就足够了，单主用来写入数据，单机几万QPS，多用来查询数据，多个实例可以提供每秒10W的QPS。
    
    ​       如果想在实现高并发的同时，容纳大量的数据，就需要redis集群，使用redis集群之后，可以实现每秒几十万的读写并发；
    
    ​       实现了高并发，怎么样实现高可用呢？
    
    ​       如果是做主从架构部署，加上哨兵就可以，就可以实现，任何一个实例宕机，可以进行主备切换。
    
    ​     
    
    ### 我的理解：
    
    ​    redis实现高并发和高可用，主要就是两点：
    
    ​      **主从架构实现读高并发；**
    
    ​      **哨兵主备切换机制实现集群高可用。**


​    

​    

​    

  ​     

​    

​    

​    

​    

​    

​    

​    

​    

​    

​    

​    

  ​    

​    

​    

​    

​    

​    

​    

​    

  